@Article{electronics9020215,
AUTHOR = {Wei, Lijun and Wu, Jing and Long, Chengnian},
TITLE = {A Blockchain-Based Hybrid Incentive Model for Crowdsensing},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {215},
URL = {https://www.mdpi.com/2079-9292/9/2/215},
ISSN = {2079-9292},
ABSTRACT = {Crowdsensing is an emerging paradigm of data aggregation, which has a pivotal role in data-driven applications. By leveraging the recruitment, a crowdsensing system collects a large amount of data from mobile devices at a low cost. The critical issues in the development of crowdsensing are platform security, privacy protection, and incentive. However, the existing centralized, platform-based approaches suffer from the single point of failure which may result in data leakage. Besides, few previous studies have addressed the considerations of both the economic incentive and data quality. In this paper, we propose a decentralized crowdsensing architecture based on blockchain technology which will help improve the attack resistance. Furthermore, we present a hybrid incentive mechanism, which integrates the data quality, reputation, and monetary factors to encourage participants to contribute their sensing data while discouraging malicious behaviors. The effectiveness our of proposed incentive model is verified through a combination of the theory of mechanism design. The performance analysis and simulation results illustrate that the proposed hybrid incentive model is a reliable and efficient mean to promote data security and incentivizing positive conduct on the crowdsensing application.},
DOI = {10.3390/electronics9020215}
}

@misc{augenstein_generative_2020,
	title = {Generative Models for Effective {ML} on Private, Decentralized Datasets},
	url = {http://arxiv.org/abs/1911.06679},
	doi = {10.48550/arXiv.1911.06679},
	abstract = {To improve real-world applications of machine learning, experienced modelers develop intuition about their datasets, their models, and how the two interact. Manual inspection of raw data - of representative samples, of outliers, of misclassifications - is an essential tool in a) identifying and fixing problems in the data, b) generating new modeling hypotheses, and c) assigning or refining human-provided labels. However, manual data inspection is problematic for privacy sensitive datasets, such as those representing the behavior of real-world individuals. Furthermore, manual data inspection is impossible in the increasingly important setting of federated learning, where raw examples are stored at the edge and the modeler may only access aggregated outputs such as metrics or model parameters. This paper demonstrates that generative models - trained using federated methods and with formal differential privacy guarantees - can be used effectively to debug many commonly occurring data issues even when the data cannot be directly inspected. We explore these methods in applications to text with differentially private federated {RNNs} and to images using a novel algorithm for differentially private federated {GANs}.},
	publisher = {{arXiv}},
	author = {Augenstein, Sean and {McMahan}, H. Brendan and Ramage, Daniel and Ramaswamy, Swaroop and Kairouz, Peter and Chen, Mingqing and Mathews, Rajiv and Arcas, Blaise Aguera y},
	urldate = {2022-10-22},
	date = {2020-02-04},
	eprinttype = {arxiv},
	eprint = {1911.06679 [cs, stat]},
	note = {version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ma_when_2020,
	title = {When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm},
	url = {http://arxiv.org/abs/2009.09338},
	doi = {10.48550/arXiv.2009.09338},
	shorttitle = {When Federated Learning Meets Blockchain},
	abstract = {Motivated by the explosive computing capabilities at end user equipments, as well as the growing privacy concerns over sharing sensitive raw data, a new machine learning paradigm, named federated learning ({FL}) has emerged. By training models locally at each client and aggregating learning models at a central server, {FL} has the capability to avoid sharing data directly, thereby reducing privacy leakage. However, the traditional {FL} framework heavily relies on a single central server and may fall apart if such a server behaves maliciously. To address this single point of failure issue, this work investigates a blockchain assisted decentralized {FL} ({BLADE}-{FL}) framework, which can well prevent the malicious clients from poisoning the learning process, and further provides a self-motivated and reliable learning environment for clients. In detail, the model aggregation process is fully decentralized and the tasks of training for {FL} and mining for blockchain are integrated into each participant. In addition, we investigate the unique issues in this framework and provide analytical and experimental results to shed light on possible solutions.},
	publisher = {{arXiv}},
	author = {Ma, Chuan and Li, Jun and Ding, Ming and Shi, Long and Wang, Taotao and Han, Zhu and Poor, H. Vincent},
	urldate = {2022-10-19},
	date = {2020-09-19},
	eprinttype = {arxiv},
	eprint = {2009.09338 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Networking and Internet Architecture},
}

@misc{kairouz_advances_2021,
	title = {Advances and Open Problems in Federated Learning},
	url = {http://arxiv.org/abs/1912.04977},
	doi = {10.48550/arXiv.1912.04977},
	abstract = {Federated learning ({FL}) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. {FL} embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in {FL} research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
	publisher = {{arXiv}},
	author = {Kairouz, Peter and {McMahan}, H. Brendan and Avent, Brendan and Bellet, Aurélien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gascón, Adrià and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konečný, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancrède and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and Özgür, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tramèr, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
	urldate = {2022-10-19},
	date = {2021-03-08},
	eprinttype = {arxiv},
	eprint = {1912.04977 [cs, stat]},
	note = {version: 3},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{wang_blockchain-based_2021,
	title = {Blockchain-based Federated Learning: A Comprehensive Survey},
	url = {http://arxiv.org/abs/2110.02182},
	doi = {10.48550/arXiv.2110.02182},
	shorttitle = {Blockchain-based Federated Learning},
	abstract = {With the technological advances in machine learning, effective ways are available to process the huge amount of data generated in real life. However, issues of privacy and scalability will constrain the development of machine learning. Federated learning ({FL}) can prevent privacy leakage by assigning training tasks to multiple clients, thus separating the central server from the local devices. However, {FL} still suffers from shortcomings such as single-point-failure and malicious data. The emergence of blockchain provides a secure and efficient solution for the deployment of {FL}. In this paper, we conduct a comprehensive survey of the literature on blockchained {FL} ({BCFL}). First, we investigate how blockchain can be applied to federal learning from the perspective of system composition. Then, we analyze the concrete functions of {BCFL} from the perspective of mechanism design and illustrate what problems blockchain addresses specifically for {FL}. We also survey the applications of {BCFL} in reality. Finally, we discuss some challenges and future research directions.},
	publisher = {{arXiv}},
	author = {Wang, Zhilin and Hu, Qin},
	urldate = {2022-10-19},
	date = {2021-10-05},
	eprinttype = {arxiv},
	eprint = {2110.02182 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@article{kim_blockchained_2020,
	title = {Blockchained On-Device Federated Learning},
	volume = {24},
	issn = {1558-2558},
	doi = {10.1109/LCOMM.2019.2921755},
	abstract = {By leveraging blockchain, this letter proposes a blockchained federated learning ({BlockFL}) architecture where local learning model updates are exchanged and verified. This enables on-device machine learning without any centralized training data or coordination by utilizing a consensus mechanism in blockchain. Moreover, we analyze an end-to-end latency model of {BlockFL} and characterize the optimal block generation rate by considering communication, computation, and consensus delays.},
	pages = {1279--1283},
	number = {6},
	journaltitle = {{IEEE} Communications Letters},
	author = {Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
	date = {2020-06},
	keywords = {Blockchain, Computational modeling, Data models, Delays, Nickel, On-device machine learning, Servers, Training, blockchain, federated learning, latency},
}

@inproceedings{ur_rehman_towards_2020,
	title = {Towards Blockchain-Based Reputation-Aware Federated Learning},
	doi = {10.1109/INFOCOMWKSHPS50562.2020.9163027},
	abstract = {Federated learning ({FL}) is the collaborative machine learning ({ML}) technique whereby the devices collectively train and update a shared {ML} model while preserving their personal datasets. {FL} systems solve the problems of communication-efficiency, bandwidth-optimization, and privacy-preservation. Despite the potential benefits of {FL}, one centralized shared {ML} model across all the devices produce coarse-grained predictions which, in essence, are not required in many application areas involving personalized prediction services. In this paper, we present a novel concept of fine-grained {FL} to decentralize the shared {ML} models on the edge servers. We then present a formal extended definition of fine-grained {FL} process in mobile edge computing systems. In addition, we define the core requirements of fine-grained {FL} systems including personalization, decentralization, fine-grained {FL}, incentive mechanisms, trust, activity monitoring, heterogeneity and context-awareness, model synchronization, and communication and bandwidth-efficiency. Moreover, we present the concept of blockchain-based reputation-aware fine-grained {FL} in order to ensure trustworthy collaborative training in mobile edge computing systems. Finally, we perform the qualitative comparison of proposed approach with state-of-the-art related work and found some promising initial results.},
	eventtitle = {{IEEE} {INFOCOM} 2020 - {IEEE} Conference on Computer Communications Workshops ({INFOCOM} {WKSHPS})},
	pages = {183--188},
	booktitle = {{IEEE} {INFOCOM} 2020 - {IEEE} Conference on Computer Communications Workshops ({INFOCOM} {WKSHPS})},
	author = {ur Rehman, Muhammad Habib and Salah, Khaled and Damiani, Ernesto and Svetinovic, Davor},
	date = {2020-07},
	keywords = {Cloud computing, Data models, Machine learning, Privacy, Servers, Training, blockchain, federated learning, machine learning, mobile edge computing, reputation, trust},
}

@article{toyoda_blockchain-enabled_2020,
	title = {Blockchain-Enabled Federated Learning With Mechanism Design},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3043037},
	abstract = {Federated learning ({FL}) is a promising decentralized deep learning technique that allows users to collaboratively update models without sharing their own data. However, due to its decentralized nature, no one can monitor workers' behavior, and they may thus deviate protocols (e.g., participating without updating any models). To solve this problem, many researchers have proposed blockchain-enabled {FL} to reward workers (or users) with cryptocurrencies to encourage workers to follow the protocols. However, there is a lack of theoretical discussions concerning how such rewards impact workers' behavior and how much should be given to workers. In this article, we propose a mechanism-design-oriented {FL} protocol on a public blockchain network. Mechanism design ({MD}) is often used to make a rule intended to achieve a specific goal. With {MD} in mind, we introduce the concept of competition into blockchain-based {FL} so that only workers who have contributed well can obtain rewards, which naturally prevents workers from deviating from the protocol. We then mathematically answer the following questions with contest theory, a novel field of study in economics: i) What behavior will workers take?; ii) how much effort should workers exert to maximize their profits?; iii) how many workers should be rewarded?; and iv) what is the best proportion for reward distribution?},
	pages = {219744--219756},
	journaltitle = {{IEEE} Access},
	author = {Toyoda, Kentaroh and Zhao, Jun and Zhang, Allan Neng Sheng and Mathiopoulos, P. Takis},
	date = {2020},
	keywords = {Biological system modeling, Blockchain, Cryptography, Data models, Federated learning, Protocols, Smart contracts, Task analysis, blockchain, contest theory, decentralized deep learning, mechanism design},
}

@inproceedings{toyoda_mechanism_2019,
	title = {Mechanism Design for An Incentive-aware Blockchain-enabled Federated Learning Platform},
	doi = {10.1109/BigData47090.2019.9006344},
	abstract = {Recent technological evolution enables Artificial Intelligence ({AI}) model training by users' mobile devices, which accelerates decentralized big data analysis. In particular, Federated Learning ({FL}) is a key enabler to realize decentralized {AI} model update without user's privacy disclosure. However, since the behaviour of workers, who are assigned a training task, cannot be monitored, the state-of-the-art methods require a special hardware and/or cryptography to force the workers behave honestly, which hinders the realization. Furthermore, although blockchain-enabled {FL} has been proposed to give workers reward, any rigorous reward policy design has not been discussed. In this paper, to tackle these issues, we present a novel method using mechanism design, which is an economic approach to realize desired objectives under the situation that participants act rationally. The key idea is to introduce repeated competition for {FL} so that any rational worker follows the protocol and maximize their profits. With mechanism design, we propose a generic full-fledged protocol design for {FL} on a public blockchain. We also theoretically clarify incentive compatibility based on contest theory which is an auction-based game theory in economics.},
	eventtitle = {2019 {IEEE} International Conference on Big Data (Big Data)},
	pages = {395--403},
	booktitle = {2019 {IEEE} International Conference on Big Data (Big Data)},
	author = {Toyoda, Kentaroh and Zhang, Allan N.},
	date = {2019-12},
	keywords = {Bitcoin, Computational modeling, Contracts, Data models, Machine learning},
}

@inproceedings{martinez_record_2019,
	title = {Record and Reward Federated Learning Contributions with Blockchain},
	doi = {10.1109/CyberC.2019.00018},
	abstract = {Although Federated Learning allows for participants to contribute their local data without it being revealed, it faces issues in data security and in accurately paying participants for quality data contributions. In this paper, we propose an {EOS} Blockchain design and workflow to establish data security, a novel validation error based metric upon which we qualify gradient uploads for payment, and implement a small example of our blockchain Federated Learning model to analyze its performance.},
	eventtitle = {2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery ({CyberC})},
	pages = {50--57},
	booktitle = {2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery ({CyberC})},
	author = {Martinez, Ismael and Francis, Sreya and Hafid, Abdelhakim Senhaji},
	date = {2019-10},
	keywords = {Blockchain, Data models, Distributed Machine Learning, Distributed databases, Earth Observing System, Federated Learning, Machine learning, Smart contracts, Training, blockchain, class sampled validation error},
}

@inproceedings{ma_transparent_2021,
	title = {Transparent Contribution Evaluation for Secure Federated Learning on Blockchain},
	doi = {10.1109/ICDEW53142.2021.00023},
	abstract = {Federated Learning is a promising machine learning paradigm when multiple parties collaborate to build a high-quality machine learning model. Nonetheless, these parties are only willing to participate when given enough incentives, such as a fair reward based on their contributions. Many studies explored Shapley value based methods to evaluate each party's contribution to the learned model. However, they commonly assume a semi-trusted server to train the model and evaluate the data owners' model contributions, which lacks transparency and may hinder the success of federated learning in practice. In this work, we propose a blockchain-based federated learning framework and a protocol to transparently evaluate each participant's contribution. Our framework protects all parties' privacy in the model building phase and transparently evaluates contributions based on the model updates. The experiment with the handwritten digits dataset demonstrates that the proposed method can effectively evaluate the contributions.},
	eventtitle = {2021 {IEEE} 37th International Conference on Data Engineering Workshops ({ICDEW})},
	pages = {88--91},
	booktitle = {2021 {IEEE} 37th International Conference on Data Engineering Workshops ({ICDEW})},
	author = {Ma, Shuaicheng and Cao, Yang and Xiong, Li},
	date = {2021-04},
	note = {{ISSN}: 2473-3490},
	keywords = {Blockchain, Buildings, Collaborative work, Conferences, Contribution Evaluation, Federated Learning, Machine learning, Privacy, Protocols, Transparency},
}

@inproceedings{hou_systematic_2021,
	title = {A Systematic Literature Review of Blockchain-based Federated Learning: Architectures, Applications and Issues},
	doi = {10.1109/ICTC51749.2021.9441499},
	shorttitle = {A Systematic Literature Review of Blockchain-based Federated Learning},
	abstract = {Federal learning ({FL}) can realize a distributed training machine learning models in multiple devices while protecting their data privacy, but some defect still exists such as single point failure and lack of motivation. Blockchain as a distributed ledger can be utilized to provide a novel {FL} framework to address those issues. This paper aims to discuss how the blockchain technology is employed to compensate for shortcomings in {FL}. A systematic literature review is conducted to investigate existing {FL} problems and to summarize knowledge about the existing Blockchain-based {FL} ({BFL}). The differences among these collected {BFL} architectures are presented and discussed, and the applications of {BFL} are categorized and analyzed. Finally, some suggestions for future development and application of {BFL} are discussed.},
	eventtitle = {2021 2nd Information Communication Technologies Conference ({ICTC})},
	pages = {302--307},
	booktitle = {2021 2nd Information Communication Technologies Conference ({ICTC})},
	author = {Hou, Dongkun and Zhang, Jie and Man, Ka Lok and Ma, Jieming and Peng, Zitian},
	date = {2021-05},
	keywords = {Bibliographies, Blockchain, Data privacy, Distributed ledger, Federated Learning, Machine learning, Systematic Literature Review, Systematics, Training},
}

@inproceedings{bao_flchain_2019,
	location = {{QingDao}, China},
	title = {{FLChain}: A Blockchain for Auditable Federated Learning with Trust and Incentive},
	isbn = {9781728140247},
	url = {https://ieeexplore.ieee.org/document/8905038/},
	doi = {10.1109/BIGCOM.2019.00030},
	shorttitle = {{FLChain}},
	eventtitle = {2019 5th International Conference on Big Data Computing and Communications ({BIGCOM})},
	pages = {151--159},
	booktitle = {2019 5th International Conference on Big Data Computing and Communications ({BIGCOM})},
	publisher = {{IEEE}},
	author = {Bao, Xianglin and Su, Cheng and Xiong, Yan and Huang, Wenchao and Hu, Yifei},
	urldate = {2022-10-19},
	date = {2019-08},
}

@article{ali_integration_2021,
	title = {Integration of blockchain and federated learning for Internet of Things: Recent advances and future challenges},
	volume = {108},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404821001796},
	doi = {10.1016/j.cose.2021.102355},
	shorttitle = {Integration of blockchain and federated learning for Internet of Things},
	pages = {102355},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Ali, Mansoor and Karimipour, Hadis and Tariq, Muhammad},
	urldate = {2022-10-19},
	date = {2021-09},
	langid = {english},
}

@misc{ratner_mlsys_2019,
	title = {{MLSys}: The New Frontier of Machine Learning Systems},
	url = {http://arxiv.org/abs/1904.03257},
	shorttitle = {{MLSys}},
	abstract = {Machine learning ({ML}) techniques are enjoying rapidly increasing adoption. However, designing and implementing the systems that support {ML} models in real-world deployments remains a signiﬁcant obstacle, in large part due to the radically different development and deployment proﬁle of modern {ML} methods, and the range of practical concerns that come with broader adoption. We propose to foster a new systems machine learning research community at the intersection of the traditional systems and {ML} communities, focused on topics such as hardware systems for {ML}, software systems for {ML}, and {ML} optimized for metrics beyond predictive accuracy. To do this, we describe a new conference, {MLSys}, that explicitly targets research at the intersection of systems and machine learning with a program committee split evenly between experts in systems and {ML}, and an explicit focus on topics at the intersection of the two.},
	publisher = {{arXiv}},
	author = {Ratner, Alexander and Alistarh, Dan and Alonso, Gustavo and Andersen, David G. and Bailis, Peter and Bird, Sarah and Carlini, Nicholas and Catanzaro, Bryan and Chayes, Jennifer and Chung, Eric and Dally, Bill and Dean, Jeff and Dhillon, Inderjit S. and Dimakis, Alexandros and Dubey, Pradeep and Elkan, Charles and Fursin, Grigori and Ganger, Gregory R. and Getoor, Lise and Gibbons, Phillip B. and Gibson, Garth A. and Gonzalez, Joseph E. and Gottschlich, Justin and Han, Song and Hazelwood, Kim and Huang, Furong and Jaggi, Martin and Jamieson, Kevin and Jordan, Michael I. and Joshi, Gauri and Khalaf, Rania and Knight, Jason and Konečný, Jakub and Kraska, Tim and Kumar, Arun and Kyrillidis, Anastasios and Lakshmiratan, Aparna and Li, Jing and Madden, Samuel and {McMahan}, H. Brendan and Meijer, Erik and Mitliagkas, Ioannis and Monga, Rajat and Murray, Derek and Olukotun, Kunle and Papailiopoulos, Dimitris and Pekhimenko, Gennady and Rekatsinas, Theodoros and Rostamizadeh, Afshin and Ré, Christopher and De Sa, Christopher and Sedghi, Hanie and Sen, Siddhartha and Smith, Virginia and Smola, Alex and Song, Dawn and Sparks, Evan and Stoica, Ion and Sze, Vivienne and Udell, Madeleine and Vanschoren, Joaquin and Venkataraman, Shivaram and Vinayak, Rashmi and Weimer, Markus and Wilson, Andrew Gordon and Xing, Eric and Zaharia, Matei and Zhang, Ce and Talwalkar, Ameet},
	urldate = {2022-09-30},
	date = {2019-12-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.03257 [cs, stat]},
	keywords = {Computer Science - Databases, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Software Engineering, Statistics - Machine Learning},
}

@article{nguyen_federated_2021,
	title = {Federated Learning Meets Blockchain in Edge Computing: Opportunities and Challenges},
	volume = {8},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9403374/},
	doi = {10.1109/JIOT.2021.3072611},
	shorttitle = {Federated Learning Meets Blockchain in Edge Computing},
	pages = {12806--12825},
	number = {16},
	journaltitle = {{IEEE} Internet of Things Journal},
	shortjournal = {{IEEE} Internet Things J.},
	author = {Nguyen, Dinh C. and Ding, Ming and Pham, Quoc-Viet and Pathirana, Pubudu N. and Le, Long Bao and Seneviratne, Aruna and Li, Jun and Niyato, Dusit and Poor, H. Vincent},
	urldate = {2022-10-17},
	date = {2021-08-15},
}
