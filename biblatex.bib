@Article{electronics9020215,
AUTHOR = {Wei, Lijun and Wu, Jing and Long, Chengnian},
TITLE = {A Blockchain-Based Hybrid Incentive Model for Crowdsensing},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {215},
URL = {https://www.mdpi.com/2079-9292/9/2/215},
ISSN = {2079-9292},
ABSTRACT = {Crowdsensing is an emerging paradigm of data aggregation, which has a pivotal role in data-driven applications. By leveraging the recruitment, a crowdsensing system collects a large amount of data from mobile devices at a low cost. The critical issues in the development of crowdsensing are platform security, privacy protection, and incentive. However, the existing centralized, platform-based approaches suffer from the single point of failure which may result in data leakage. Besides, few previous studies have addressed the considerations of both the economic incentive and data quality. In this paper, we propose a decentralized crowdsensing architecture based on blockchain technology which will help improve the attack resistance. Furthermore, we present a hybrid incentive mechanism, which integrates the data quality, reputation, and monetary factors to encourage participants to contribute their sensing data while discouraging malicious behaviors. The effectiveness our of proposed incentive model is verified through a combination of the theory of mechanism design. The performance analysis and simulation results illustrate that the proposed hybrid incentive model is a reliable and efficient mean to promote data security and incentivizing positive conduct on the crowdsensing application.},
DOI = {10.3390/electronics9020215}
}

@misc{augenstein_generative_2020,
	title = {Generative Models for Effective {ML} on Private, Decentralized Datasets},
	url = {http://arxiv.org/abs/1911.06679},
	doi = {10.48550/arXiv.1911.06679},
	abstract = {To improve real-world applications of machine learning, experienced modelers develop intuition about their datasets, their models, and how the two interact. Manual inspection of raw data - of representative samples, of outliers, of misclassifications - is an essential tool in a) identifying and fixing problems in the data, b) generating new modeling hypotheses, and c) assigning or refining human-provided labels. However, manual data inspection is problematic for privacy sensitive datasets, such as those representing the behavior of real-world individuals. Furthermore, manual data inspection is impossible in the increasingly important setting of federated learning, where raw examples are stored at the edge and the modeler may only access aggregated outputs such as metrics or model parameters. This paper demonstrates that generative models - trained using federated methods and with formal differential privacy guarantees - can be used effectively to debug many commonly occurring data issues even when the data cannot be directly inspected. We explore these methods in applications to text with differentially private federated {RNNs} and to images using a novel algorithm for differentially private federated {GANs}.},
	publisher = {{arXiv}},
	author = {Augenstein, Sean and {McMahan}, H. Brendan and Ramage, Daniel and Ramaswamy, Swaroop and Kairouz, Peter and Chen, Mingqing and Mathews, Rajiv and Arcas, Blaise Aguera y},
	urldate = {2022-10-22},
	date = {2020-02-04},
	eprinttype = {arxiv},
	eprint = {1911.06679 [cs, stat]},
	note = {version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ma_when_2020,
	title = {When Federated Learning Meets Blockchain: A New Distributed Learning Paradigm},
	url = {http://arxiv.org/abs/2009.09338},
	doi = {10.48550/arXiv.2009.09338},
	shorttitle = {When Federated Learning Meets Blockchain},
	abstract = {Motivated by the explosive computing capabilities at end user equipments, as well as the growing privacy concerns over sharing sensitive raw data, a new machine learning paradigm, named federated learning ({FL}) has emerged. By training models locally at each client and aggregating learning models at a central server, {FL} has the capability to avoid sharing data directly, thereby reducing privacy leakage. However, the traditional {FL} framework heavily relies on a single central server and may fall apart if such a server behaves maliciously. To address this single point of failure issue, this work investigates a blockchain assisted decentralized {FL} ({BLADE}-{FL}) framework, which can well prevent the malicious clients from poisoning the learning process, and further provides a self-motivated and reliable learning environment for clients. In detail, the model aggregation process is fully decentralized and the tasks of training for {FL} and mining for blockchain are integrated into each participant. In addition, we investigate the unique issues in this framework and provide analytical and experimental results to shed light on possible solutions.},
	publisher = {{arXiv}},
	author = {Ma, Chuan and Li, Jun and Ding, Ming and Shi, Long and Wang, Taotao and Han, Zhu and Poor, H. Vincent},
	urldate = {2022-10-19},
	date = {2020-09-19},
	eprinttype = {arxiv},
	eprint = {2009.09338 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Networking and Internet Architecture},
}

@misc{kairouz_advances_2021,
	title = {Advances and Open Problems in Federated Learning},
	url = {http://arxiv.org/abs/1912.04977},
	doi = {10.48550/arXiv.1912.04977},
	abstract = {Federated learning ({FL}) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. {FL} embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in {FL} research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
	publisher = {{arXiv}},
	author = {Kairouz, Peter and {McMahan}, H. Brendan and Avent, Brendan and Bellet, Aurélien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gascón, Adrià and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konečný, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancrède and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and Özgür, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tramèr, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
	urldate = {2022-10-19},
	date = {2021-03-08},
	eprinttype = {arxiv},
	eprint = {1912.04977 [cs, stat]},
	note = {version: 3},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{wang_blockchain-based_2021,
	title = {Blockchain-based Federated Learning: A Comprehensive Survey},
	url = {http://arxiv.org/abs/2110.02182},
	doi = {10.48550/arXiv.2110.02182},
	shorttitle = {Blockchain-based Federated Learning},
	abstract = {With the technological advances in machine learning, effective ways are available to process the huge amount of data generated in real life. However, issues of privacy and scalability will constrain the development of machine learning. Federated learning ({FL}) can prevent privacy leakage by assigning training tasks to multiple clients, thus separating the central server from the local devices. However, {FL} still suffers from shortcomings such as single-point-failure and malicious data. The emergence of blockchain provides a secure and efficient solution for the deployment of {FL}. In this paper, we conduct a comprehensive survey of the literature on blockchained {FL} ({BCFL}). First, we investigate how blockchain can be applied to federal learning from the perspective of system composition. Then, we analyze the concrete functions of {BCFL} from the perspective of mechanism design and illustrate what problems blockchain addresses specifically for {FL}. We also survey the applications of {BCFL} in reality. Finally, we discuss some challenges and future research directions.},
	publisher = {{arXiv}},
	author = {Wang, Zhilin and Hu, Qin},
	urldate = {2022-10-19},
	date = {2021-10-05},
	eprinttype = {arxiv},
	eprint = {2110.02182 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@article{kim_blockchained_2020,
	title = {Blockchained On-Device Federated Learning},
	volume = {24},
	issn = {1558-2558},
	doi = {10.1109/LCOMM.2019.2921755},
	abstract = {By leveraging blockchain, this letter proposes a blockchained federated learning ({BlockFL}) architecture where local learning model updates are exchanged and verified. This enables on-device machine learning without any centralized training data or coordination by utilizing a consensus mechanism in blockchain. Moreover, we analyze an end-to-end latency model of {BlockFL} and characterize the optimal block generation rate by considering communication, computation, and consensus delays.},
	pages = {1279--1283},
	number = {6},
	journaltitle = {{IEEE} Communications Letters},
	author = {Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
	date = {2020-06},
	keywords = {Blockchain, Computational modeling, Data models, Delays, Nickel, On-device machine learning, Servers, Training, blockchain, federated learning, latency},
}

@inproceedings{ur_rehman_towards_2020,
	title = {Towards Blockchain-Based Reputation-Aware Federated Learning},
	doi = {10.1109/INFOCOMWKSHPS50562.2020.9163027},
	abstract = {Federated learning ({FL}) is the collaborative machine learning ({ML}) technique whereby the devices collectively train and update a shared {ML} model while preserving their personal datasets. {FL} systems solve the problems of communication-efficiency, bandwidth-optimization, and privacy-preservation. Despite the potential benefits of {FL}, one centralized shared {ML} model across all the devices produce coarse-grained predictions which, in essence, are not required in many application areas involving personalized prediction services. In this paper, we present a novel concept of fine-grained {FL} to decentralize the shared {ML} models on the edge servers. We then present a formal extended definition of fine-grained {FL} process in mobile edge computing systems. In addition, we define the core requirements of fine-grained {FL} systems including personalization, decentralization, fine-grained {FL}, incentive mechanisms, trust, activity monitoring, heterogeneity and context-awareness, model synchronization, and communication and bandwidth-efficiency. Moreover, we present the concept of blockchain-based reputation-aware fine-grained {FL} in order to ensure trustworthy collaborative training in mobile edge computing systems. Finally, we perform the qualitative comparison of proposed approach with state-of-the-art related work and found some promising initial results.},
	eventtitle = {{IEEE} {INFOCOM} 2020 - {IEEE} Conference on Computer Communications Workshops ({INFOCOM} {WKSHPS})},
	pages = {183--188},
	booktitle = {{IEEE} {INFOCOM} 2020 - {IEEE} Conference on Computer Communications Workshops ({INFOCOM} {WKSHPS})},
	author = {ur Rehman, Muhammad Habib and Salah, Khaled and Damiani, Ernesto and Svetinovic, Davor},
	date = {2020-07},
	keywords = {Cloud computing, Data models, Machine learning, Privacy, Servers, Training, blockchain, federated learning, machine learning, mobile edge computing, reputation, trust},
}

@article{toyoda_blockchain-enabled_2020,
	title = {Blockchain-Enabled Federated Learning With Mechanism Design},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3043037},
	abstract = {Federated learning ({FL}) is a promising decentralized deep learning technique that allows users to collaboratively update models without sharing their own data. However, due to its decentralized nature, no one can monitor workers' behavior, and they may thus deviate protocols (e.g., participating without updating any models). To solve this problem, many researchers have proposed blockchain-enabled {FL} to reward workers (or users) with cryptocurrencies to encourage workers to follow the protocols. However, there is a lack of theoretical discussions concerning how such rewards impact workers' behavior and how much should be given to workers. In this article, we propose a mechanism-design-oriented {FL} protocol on a public blockchain network. Mechanism design ({MD}) is often used to make a rule intended to achieve a specific goal. With {MD} in mind, we introduce the concept of competition into blockchain-based {FL} so that only workers who have contributed well can obtain rewards, which naturally prevents workers from deviating from the protocol. We then mathematically answer the following questions with contest theory, a novel field of study in economics: i) What behavior will workers take?; ii) how much effort should workers exert to maximize their profits?; iii) how many workers should be rewarded?; and iv) what is the best proportion for reward distribution?},
	pages = {219744--219756},
	journaltitle = {{IEEE} Access},
	author = {Toyoda, Kentaroh and Zhao, Jun and Zhang, Allan Neng Sheng and Mathiopoulos, P. Takis},
	date = {2020},
	keywords = {Biological system modeling, Blockchain, Cryptography, Data models, Federated learning, Protocols, Smart contracts, Task analysis, blockchain, contest theory, decentralized deep learning, mechanism design},
}

@inproceedings{toyoda_mechanism_2019,
	title = {Mechanism Design for An Incentive-aware Blockchain-enabled Federated Learning Platform},
	doi = {10.1109/BigData47090.2019.9006344},
	abstract = {Recent technological evolution enables Artificial Intelligence ({AI}) model training by users' mobile devices, which accelerates decentralized big data analysis. In particular, Federated Learning ({FL}) is a key enabler to realize decentralized {AI} model update without user's privacy disclosure. However, since the behaviour of workers, who are assigned a training task, cannot be monitored, the state-of-the-art methods require a special hardware and/or cryptography to force the workers behave honestly, which hinders the realization. Furthermore, although blockchain-enabled {FL} has been proposed to give workers reward, any rigorous reward policy design has not been discussed. In this paper, to tackle these issues, we present a novel method using mechanism design, which is an economic approach to realize desired objectives under the situation that participants act rationally. The key idea is to introduce repeated competition for {FL} so that any rational worker follows the protocol and maximize their profits. With mechanism design, we propose a generic full-fledged protocol design for {FL} on a public blockchain. We also theoretically clarify incentive compatibility based on contest theory which is an auction-based game theory in economics.},
	eventtitle = {2019 {IEEE} International Conference on Big Data (Big Data)},
	pages = {395--403},
	booktitle = {2019 {IEEE} International Conference on Big Data (Big Data)},
	author = {Toyoda, Kentaroh and Zhang, Allan N.},
	date = {2019-12},
	keywords = {Bitcoin, Computational modeling, Contracts, Data models, Machine learning},
}

@inproceedings{martinez_record_2019,
	title = {Record and Reward Federated Learning Contributions with Blockchain},
	doi = {10.1109/CyberC.2019.00018},
	abstract = {Although Federated Learning allows for participants to contribute their local data without it being revealed, it faces issues in data security and in accurately paying participants for quality data contributions. In this paper, we propose an {EOS} Blockchain design and workflow to establish data security, a novel validation error based metric upon which we qualify gradient uploads for payment, and implement a small example of our blockchain Federated Learning model to analyze its performance.},
	eventtitle = {2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery ({CyberC})},
	pages = {50--57},
	booktitle = {2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery ({CyberC})},
	author = {Martinez, Ismael and Francis, Sreya and Hafid, Abdelhakim Senhaji},
	date = {2019-10},
	keywords = {Blockchain, Data models, Distributed Machine Learning, Distributed databases, Earth Observing System, Federated Learning, Machine learning, Smart contracts, Training, blockchain, class sampled validation error},
}

@inproceedings{awan_poster_2019,
author = {Awan, Sana and Li, Fengjun and Luo, Bo and Liu, Mei},
title = {Poster: A Reliable and Accountable Privacy-Preserving Federated Learning Framework Using the Blockchain},
year = {2019},
isbn = {9781450367479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319535.3363256},
doi = {10.1145/3319535.3363256},
abstract = {Federated learning (FL) is promising in supporting collaborative learning applications that involve large datasets, massively distributed data owners and unreliable network connectivity. To protect data privacy, existing FL approaches adopt (k,n)-threshold secret sharing schemes, based on the semi-honest assumption for clients, to enable secure multiparty computation in local model update exchange which deals with random client dropouts at the cost of increasing data size. These approaches adopt the semi-honest assumption for clients, therefore they are vulnerable to malicious clients. In this work, we propose a blockchain-based privacy-preserving federated learning (BC-based PPFL) framework, which leverages the immutability and decentralized trust properties of blockchain to provide provenance of model updates. Our proof-of-concept implementation of BC-based PPFL demonstrates it is practical for secure aggregation of local model updates in the federated setting.},
booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2561–2563},
numpages = {3},
keywords = {blockchain, federated learning, privacy},
location = {London, United Kingdom},
series = {CCS '19}
}

@INPROCEEDINGS{korkmaz_chainfl_2020,  author={Korkmaz, Caner and Kocas, Halil Eralp and Uysal, Ahmet and Masry, Ahmed and Ozkasap, Oznur and Akgun, Baris},  booktitle={2020 Second International Conference on Blockchain Computing and Applications (BCCA)},   title={Chain FL: Decentralized Federated Machine Learning via Blockchain},   year={2020},  volume={},  number={},  pages={140-146},  doi={10.1109/BCCA50787.2020.9274451}}

@article{sharma_2020,
title = {Blockchain and federated learning-based distributed computing defence framework for sustainable society},
journal = {Sustainable Cities and Society},
volume = {59},
pages = {102220},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102220},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720302079},
author = {Pradip Kumar Sharma and Jong Hyuk Park and Kyungeun Cho},
keywords = {Distributed computing, Internet of battle things, Sustainable society, Blockchain, Federated learning},
abstract = {Ensuring social security through the defense organization determines the creation of links between the army and society. Realizing the benefits of the Internet of Battle Things in the defense system can perfectly monetize intelligence and strengthen the armed forces. It establishes a network for strong connectivity in the army with good coordination between complex processes to effectively edge out the enemies. However, this new technology poses organizational and national security challenges that present both opportunities and obstacles. The current framework of the defense IoT network for sustainable society is not adequate enough to make actionable situational awareness decisions in order to infer the state of the battlefield while preserving the privacy of sensitive data. In this paper, we propose a distributed computing defence framework for sustainable society using the features of blockchain technology and federated learning. The proposed model presents an algorithm to meet the challenges of limited training data in order to obtain high accuracy and avoid a reason specific model. To evaluate the effectiveness of the proposed model, we prepare the dataset and investigate the performance of our framework in various scenarios. The result outcomes are promising in terms of accuracy and loss compared to baseline approach.}
}


@Article{li_crowdsfl_2020,
AUTHOR = {Li, Ziyuan and Liu, Jian and Hao, Jialu and Wang, Huimei and Xian, Ming},
TITLE = {CrowdSFL: A Secure Crowd Computing Framework Based on Blockchain and Federated Learning},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {773},
URL = {https://www.mdpi.com/2079-9292/9/5/773},
ISSN = {2079-9292},
ABSTRACT = {Over the years, the flourish of crowd computing has enabled enterprises to accomplish computing tasks through crowdsourcing in a large-scale and high-quality manner, and therefore how to efficiently and securely implement crowd computing becomes a hotspot. Some recent work innovatively adopted a P2P (peer-to-peer) network as the communication environment of crowdsourcing. Based on its decentralized control, issues like single-point-of-failure or DDoS attack can be overcome to some extent, but the huge computing capacity and storage costs required by this scheme is always unbearable. Federated learning is a distributed machine learning that supports local storage of data, and clients implement training through interactive gradient values. In our work, we combine blockchain with federated learning and propose a crowdsourcing framework named CrowdSFL, that users can implement crowdsourcing with less overhead and higher security. In addition, to protect the privacy of participants, we design a new re-encryption algorithm based on Elgamal to ensure that interactive values and other information will not be exposed to other participants outside the workflow. Finally, we have proved through experiments that our framework is superior to some similar work in accuracy, efficiency, and overhead.},
DOI = {10.3390/electronics9050773}
}

@inproceedings{guo_2020,
author = {Guo, Shaoyong and Xiang, Baoyu and Xia, Xuwei and Yan, Zhenhua and Li, Yongliang},
year = {2020},
month = {11},
pages = {},
title = {Blockchain and Federated Learning Based Data Security Sharing Mechanism Over Smart City},
doi = {10.21203/rs.3.rs-104012/v1}
}

@article{lu_2021,  author={Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},  journal={IEEE Network},   title={Blockchain and Federated Learning for 5G Beyond},   year={2021},  volume={35},  number={1},  pages={219-225},  doi={10.1109/MNET.011.1900598}}

@inproceedings{ma_2021,
	doi = {10.1109/icdew53142.2021.00023},
  
	url = {https://doi.org/10.1109%2Ficdew53142.2021.00023},
  
	year = 2021,
	month = {apr},
  
	publisher = {{IEEE}
},
  
	author = {Shuaicheng Ma and Yang Cao and Li Xiong},
  
	title = {Transparent Contribution Evaluation for Secure Federated Learning on Blockchain},
  
	booktitle = {2021 {IEEE} 37th International Conference on Data Engineering Workshops ({ICDEW})}
}

@article{durga_fled_2022,
  title={FLED-Block: Federated Learning Ensembled Deep Learning Blockchain Model for COVID-19 Prediction},
  author={R. Durga and E. Poovammal},
  journal={Frontiers in Public Health},
  year={2022},
  volume={10}
}

@ARTICLE{lu_2020,  author={Lu, Yunlong and Huang, Xiaohong and Dai, Yueyue and Maharjan, Sabita and Zhang, Yan},  journal={IEEE Transactions on Industrial Informatics},   title={Blockchain and Federated Learning for Privacy-Preserved Data Sharing in Industrial IoT},   year={2020},  volume={16},  number={6},  pages={4177-4186},  doi={10.1109/TII.2019.2942190}}

@misc{lee_2021,
  doi = {10.48550/ARXIV.2107.08624},
  
  url = {https://arxiv.org/abs/2107.08624},
  
  author = {Lee, Haemin and Kim, Joongheon},
  
  keywords = {Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Trends in Blockchain and Federated Learning for Data Sharing in Distributed Platforms},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{chen_2020,  author={Chen, YiTong and Chen, Qian and Xie, YuXiang},  booktitle={2020 IEEE 4th Conference on Energy Internet and Energy System Integration (EI2)},   title={A Methodology for High-efficient Federated-learning with Consortium Blockchain},   year={2020},  volume={},  number={},  pages={3090-3095},  doi={10.1109/EI250167.2020.9347025}}

@article{kumar_2021,
	doi = {10.1109/jsen.2021.3076767},
  
	url = {https://doi.org/10.1109%2Fjsen.2021.3076767},
  
	year = 2021,
	month = {jul},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {21},
  
	number = {14},
  
	pages = {16301--16314},
  
	author = {Rajesh Kumar and Abdullah Aman Khan and Jay Kumar and  Zakria and Noorbakhsh Amiri Golilarz and Simin Zhang and Yang Ting and Chengyu Zheng and Wenyong Wang},
  
	title = {Blockchain-Federated-Learning and Deep Learning Models for {COVID}-19 Detection Using {CT} Imaging},
  
	journal = {{IEEE} Sensors Journal}
}

@ARTICLE{weng_2019,  author={Weng, Jiasi and Weng, Jian and Zhang, Jilian and Li, Ming and Zhang, Yue and Luo, Weiqi},  journal={IEEE Transactions on Dependable and Secure Computing},   title={DeepChain: Auditable and Privacy-Preserving Deep Learning with Blockchain-Based Incentive},   year={2021},  volume={18},  number={5},  pages={2438-2455},  doi={10.1109/TDSC.2019.2952332}}

@article{nguyen_2020,
	doi = {10.1016/j.jnca.2020.102693},
  
	url = {https://doi.org/10.1016%2Fj.jnca.2020.102693},
  
	year = 2020,
	month = {sep},
  
	publisher = {Elsevier {BV}
},
  
	volume = {166},
  
	pages = {102693},
  
	author = {Dinh C. Nguyen and Pubudu N. Pathirana and Ming Ding and Aruna Seneviratne},
  
	title = {Blockchain for 5G and beyond networks: A state of the art survey},
  
	journal = {Journal of Network and Computer Applications}
}

@INPROCEEDINGS{kumar_2020,  author={Kumar, Swaraj and Dutta, Sandipan and Chatturvedi, Shaurya and Bhatia, MPS},  booktitle={2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)},   title={Strategies for Enhancing Training and Privacy in Blockchain Enabled Federated Learning},   year={2020},  volume={},  number={},  pages={333-340},  doi={10.1109/BigMM50055.2020.00058}}

@ARTICLE{zhang_2020,  author={Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},  journal={IEEE Transactions on Vehicular Technology},   title={Blockchain Empowered Asynchronous Federated Learning for Secure Data Sharing in Internet of Vehicles},   year={2020},  volume={69},  number={4},  pages={4298-4311},  doi={10.1109/TVT.2020.2973651}}

@INPROCEEDINGS{otoum_2020,  author={Otoum, Safa and Al Ridhawi, Ismaeel and Mouftah, Hussein T.},  booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference},   title={Blockchain-Supported Federated Learning for Trustworthy Vehicular Networks},   year={2020},  volume={},  number={},  pages={1-6},  doi={10.1109/GLOBECOM42002.2020.9322159}}

@article{li_2021,
	doi = {10.1109/mnet.011.2000263},
  
	url = {https://doi.org/10.1109%2Fmnet.011.2000263},
  
	year = 2021,
	month = {jan},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {35},
  
	number = {1},
  
	pages = {234--241},
  
	author = {Yuzheng Li and Chuan Chen and Nan Liu and Huawei Huang and Zibin Zheng and Qiang Yan},
  
	title = {A Blockchain-Based Decentralized Federated Learning Framework with Committee Consensus},
  
	journal = {{IEEE} Network}
}

@article{liu_2020,
	doi = {10.1109/mwc.01.1900525},
  
	url = {https://doi.org/10.1109%2Fmwc.01.1900525},
  
	year = 2020,
	month = {aug},
  
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {27},
  
	number = {4},
  
	pages = {24--31},
  
	author = {Yi Liu and Jialiang Peng and Jiawen Kang and Abdullah M. Iliyasu and Dusit Niyato and Ahmed A. Abd El-Latif},
  
	title = {A Secure Federated Learning Framework for 5G Networks},
  
	journal = {{IEEE} Wireless Communications}
}

@ARTICLE{9170905,  author={Lu, Yunlong and Huang, Xiaohong and Zhang, Ke and Maharjan, Sabita and Zhang, Yan},  journal={IEEE Transactions on Industrial Informatics},   title={Low-Latency Federated Learning and Blockchain for Edge Association in Digital Twin Empowered 6G Networks},   year={2021},  volume={17},  number={7},  pages={5098-5107},  doi={10.1109/TII.2020.3017668}}

@book{xu_bafl_2021,
	title = {{BAFL}: {An} {Efficient} {Blockchain}-{Based} {Asynchronous} {Federated} {Learning} {Framework}},
	isbn = {9781665427449},
	shorttitle = {{BAFL}},
	url = {https://dro.deakin.edu.au/articles/conference_contribution/BAFL_An_Efficient_Blockchain-Based_Asynchronous_Federated_Learning_Framework/20622720/1},
	abstract = {BAFL: An Efficient Blockchain-Based Asynchronous Federated Learning Framework},
	language = {en},
	urldate = {2022-11-29},
	publisher = {Deakin University},
	author = {Xu, Chenhao and Qu, Youyang and Eklund, Peter and Xiang, Yong and Gao, Longxiang},
	month = jan,
	year = {2021},
}

@ARTICLE{kang_2019,  author={Kang, Jiawen and Xiong, Zehui and Niyato, Dusit and Xie, Shengli and Zhang, Junshan},  journal={IEEE Internet of Things Journal},   title={Incentive Mechanism for Reliable Federated Learning: A Joint Optimization Approach to Combining Reputation and Contract Theory},   year={2019},  volume={6},  number={6},  pages={10700-10714},  doi={10.1109/JIOT.2019.2940820}}

@Inbook{liu_fedcoin_2020,
author="Liu, Yuan
and Ai, Zhengpeng
and Sun, Shuai
and Zhang, Shuangfeng
and Liu, Zelei
and Yu, Han",
editor="Yang, Qiang
and Fan, Lixin
and Yu, Han",
title="FedCoin: A Peer-to-Peer Payment System for Federated Learning",
bookTitle="Federated Learning: Privacy and Incentive",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="125--138",
abstract="Federated learning (FL) is an emerging collaborative machine learning method to train models on distributed datasets with privacy concerns. To properly incentivize data owners to contribute their efforts, Shapley Value (SV) is often adopted to fairly and quantitatively assess their contributions. However, the calculation of SV is time-consuming and computationally costly. In this chapter, we propose FedCoin, a blockchain-based peer-to-peer payment system for FL to enable a feasible SV based profit distribution. In FedCoin, blockchain consensus entities calculate SVs and a new block is created based on the proof of Shapley (PoSap) protocol. It is in contrast to the popular BitCoin network where consensus entities ``mine'' new blocks by solving meaningless puzzles. Based on the computed SVs, we propose a scheme for dividing the incentive payoffs among FL participants with non-repudiation and tamper-resistance properties. Experimental results based on real-world data show that FedCoin can promote high-quality data from FL participants through accurately computing SVs with an upper bound on the computational resources required for reaching block consensus. It opens opportunities for non-data owners to play a role in FL.",
isbn="978-3-030-63076-8",
doi="10.1007/978-3-030-63076-8_9",
url="https://doi.org/10.1007/978-3-030-63076-8_9"
}

@ARTICLE{lin_2022,  author={Lin, Xi and Wu, Jun and Bashir, Ali Kashif and Li, Jianhua and Yang, Wu and Piran, Md. Jalil},  journal={IEEE Internet of Things Journal},   title={Blockchain-Based Incentive Energy-Knowledge Trading in IoT: Joint Power Transfer and AI Design},   year={2022},  volume={9},  number={16},  pages={14685-14698},  doi={10.1109/JIOT.2020.3024246}}

@ARTICLE{wang_2020,  author={Wang, Yuntao and Su, Zhou and Zhang, Ning and Benslimane, Abderrahim},  journal={IEEE Transactions on Network Science and Engineering},   title={Learning in the Air: Secure Federated Learning for UAV-Assisted Crowdsensing},   year={2021},  volume={8},  number={2},  pages={1055-1069},  doi={10.1109/TNSE.2020.3014385}}

@misc{nguyen_2021,
  doi = {10.48550/ARXIV.2112.02870},
  
  url = {https://arxiv.org/abs/2112.02870},
  
  author = {Nguyen, Lam Duc and Pandey, Shashi Raj and Beatriz, Soret and Broering, Arne and Popovski, Petar},
  
  keywords = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Marketplace for Trading AI Models based on Blockchain and Incentives for IoT Data},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{chaabene_2022,
  doi = {10.48550/ARXIV.2206.04731},
  
  url = {https://arxiv.org/abs/2206.04731},
  
  author = {Chaabene, Riadh Ben and Amayed, Darine and Cheriet, Mohamed},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Cryptography and Security (cs.CR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Leveraging Centric Data Federated Learning Using Blockchain For Integrity Assurance},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@ARTICLE{rahmadika_2022,  author={Rahmadika, Sandi and Astillo, Philip Virgil and Choudhary, Gaurav and Duguma, Daniel Gerbi and Sharma, Vishal and You, Ilsun},  journal={IEEE Journal of Biomedical and Health Informatics},   title={Blockchain-based Privacy Preservation Scheme for Misbehavior Detection in Lightweight IoMT Devices},   year={2022},  volume={},  number={},  pages={1-13},  doi={10.1109/JBHI.2022.3187037}}

@misc{pandey_2022,
  doi = {10.48550/ARXIV.2209.09775},
  
  url = {https://arxiv.org/abs/2209.09775},
  
  author = {Pandey, Shashi Raj and Nguyen, Lam Duc and Popovski, Petar},
  
  keywords = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), Computer Science and Game Theory (cs.GT), Networking and Internet Architecture (cs.NI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {FedToken: Tokenized Incentives for Data Contribution in Federated Learning},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{ma_transparent_2021,
	title = {Transparent Contribution Evaluation for Secure Federated Learning on Blockchain},
	doi = {10.1109/ICDEW53142.2021.00023},
	abstract = {Federated Learning is a promising machine learning paradigm when multiple parties collaborate to build a high-quality machine learning model. Nonetheless, these parties are only willing to participate when given enough incentives, such as a fair reward based on their contributions. Many studies explored Shapley value based methods to evaluate each party's contribution to the learned model. However, they commonly assume a semi-trusted server to train the model and evaluate the data owners' model contributions, which lacks transparency and may hinder the success of federated learning in practice. In this work, we propose a blockchain-based federated learning framework and a protocol to transparently evaluate each participant's contribution. Our framework protects all parties' privacy in the model building phase and transparently evaluates contributions based on the model updates. The experiment with the handwritten digits dataset demonstrates that the proposed method can effectively evaluate the contributions.},
	eventtitle = {2021 {IEEE} 37th International Conference on Data Engineering Workshops ({ICDEW})},
	pages = {88--91},
	booktitle = {2021 {IEEE} 37th International Conference on Data Engineering Workshops ({ICDEW})},
	author = {Ma, Shuaicheng and Cao, Yang and Xiong, Li},
	date = {2021-04},
	note = {{ISSN}: 2473-3490},
	keywords = {Blockchain, Buildings, Collaborative work, Conferences, Contribution Evaluation, Federated Learning, Machine learning, Privacy, Protocols, Transparency},
}

@inproceedings{hou_systematic_2021,
	title = {A Systematic Literature Review of Blockchain-based Federated Learning: Architectures, Applications and Issues},
	doi = {10.1109/ICTC51749.2021.9441499},
	shorttitle = {A Systematic Literature Review of Blockchain-based Federated Learning},
	abstract = {Federal learning ({FL}) can realize a distributed training machine learning models in multiple devices while protecting their data privacy, but some defect still exists such as single point failure and lack of motivation. Blockchain as a distributed ledger can be utilized to provide a novel {FL} framework to address those issues. This paper aims to discuss how the blockchain technology is employed to compensate for shortcomings in {FL}. A systematic literature review is conducted to investigate existing {FL} problems and to summarize knowledge about the existing Blockchain-based {FL} ({BFL}). The differences among these collected {BFL} architectures are presented and discussed, and the applications of {BFL} are categorized and analyzed. Finally, some suggestions for future development and application of {BFL} are discussed.},
	eventtitle = {2021 2nd Information Communication Technologies Conference ({ICTC})},
	pages = {302--307},
	booktitle = {2021 2nd Information Communication Technologies Conference ({ICTC})},
	author = {Hou, Dongkun and Zhang, Jie and Man, Ka Lok and Ma, Jieming and Peng, Zitian},
	date = {2021-05},
	keywords = {Bibliographies, Blockchain, Data privacy, Distributed ledger, Federated Learning, Machine learning, Systematic Literature Review, Systematics, Training},
}

@inproceedings{bao_flchain_2019,
	location = {{QingDao}, China},
	title = {{FLChain}: A Blockchain for Auditable Federated Learning with Trust and Incentive},
	isbn = {9781728140247},
	url = {https://ieeexplore.ieee.org/document/8905038/},
	doi = {10.1109/BIGCOM.2019.00030},
	shorttitle = {{FLChain}},
	eventtitle = {2019 5th International Conference on Big Data Computing and Communications ({BIGCOM})},
	pages = {151--159},
	booktitle = {2019 5th International Conference on Big Data Computing and Communications ({BIGCOM})},
	publisher = {{IEEE}},
	author = {Bao, Xianglin and Su, Cheng and Xiong, Yan and Huang, Wenchao and Hu, Yifei},
	urldate = {2022-10-19},
	date = {2019-08},
}

@article{ali_integration_2021,
	title = {Integration of blockchain and federated learning for Internet of Things: Recent advances and future challenges},
	volume = {108},
	issn = {01674048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404821001796},
	doi = {10.1016/j.cose.2021.102355},
	shorttitle = {Integration of blockchain and federated learning for Internet of Things},
	pages = {102355},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Ali, Mansoor and Karimipour, Hadis and Tariq, Muhammad},
	urldate = {2022-10-19},
	date = {2021-09},
	langid = {english},
}

@misc{ratner_mlsys_2019,
	title = {{MLSys}: The New Frontier of Machine Learning Systems},
	url = {http://arxiv.org/abs/1904.03257},
	shorttitle = {{MLSys}},
	abstract = {Machine learning ({ML}) techniques are enjoying rapidly increasing adoption. However, designing and implementing the systems that support {ML} models in real-world deployments remains a signiﬁcant obstacle, in large part due to the radically different development and deployment proﬁle of modern {ML} methods, and the range of practical concerns that come with broader adoption. We propose to foster a new systems machine learning research community at the intersection of the traditional systems and {ML} communities, focused on topics such as hardware systems for {ML}, software systems for {ML}, and {ML} optimized for metrics beyond predictive accuracy. To do this, we describe a new conference, {MLSys}, that explicitly targets research at the intersection of systems and machine learning with a program committee split evenly between experts in systems and {ML}, and an explicit focus on topics at the intersection of the two.},
	publisher = {{arXiv}},
	author = {Ratner, Alexander and Alistarh, Dan and Alonso, Gustavo and Andersen, David G. and Bailis, Peter and Bird, Sarah and Carlini, Nicholas and Catanzaro, Bryan and Chayes, Jennifer and Chung, Eric and Dally, Bill and Dean, Jeff and Dhillon, Inderjit S. and Dimakis, Alexandros and Dubey, Pradeep and Elkan, Charles and Fursin, Grigori and Ganger, Gregory R. and Getoor, Lise and Gibbons, Phillip B. and Gibson, Garth A. and Gonzalez, Joseph E. and Gottschlich, Justin and Han, Song and Hazelwood, Kim and Huang, Furong and Jaggi, Martin and Jamieson, Kevin and Jordan, Michael I. and Joshi, Gauri and Khalaf, Rania and Knight, Jason and Konečný, Jakub and Kraska, Tim and Kumar, Arun and Kyrillidis, Anastasios and Lakshmiratan, Aparna and Li, Jing and Madden, Samuel and {McMahan}, H. Brendan and Meijer, Erik and Mitliagkas, Ioannis and Monga, Rajat and Murray, Derek and Olukotun, Kunle and Papailiopoulos, Dimitris and Pekhimenko, Gennady and Rekatsinas, Theodoros and Rostamizadeh, Afshin and Ré, Christopher and De Sa, Christopher and Sedghi, Hanie and Sen, Siddhartha and Smith, Virginia and Smola, Alex and Song, Dawn and Sparks, Evan and Stoica, Ion and Sze, Vivienne and Udell, Madeleine and Vanschoren, Joaquin and Venkataraman, Shivaram and Vinayak, Rashmi and Weimer, Markus and Wilson, Andrew Gordon and Xing, Eric and Zaharia, Matei and Zhang, Ce and Talwalkar, Ameet},
	urldate = {2022-09-30},
	date = {2019-12-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1904.03257 [cs, stat]},
	keywords = {Computer Science - Databases, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Software Engineering, Statistics - Machine Learning},
}

@article{nguyen_federated_2021,
	title = {Federated Learning Meets Blockchain in Edge Computing: Opportunities and Challenges},
	volume = {8},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9403374/},
	doi = {10.1109/JIOT.2021.3072611},
	shorttitle = {Federated Learning Meets Blockchain in Edge Computing},
	pages = {12806--12825},
	number = {16},
	journaltitle = {{IEEE} Internet of Things Journal},
	shortjournal = {{IEEE} Internet Things J.},
	author = {Nguyen, Dinh C. and Ding, Ming and Pham, Quoc-Viet and Pathirana, Pubudu N. and Le, Long Bao and Seneviratne, Aruna and Li, Jun and Niyato, Dusit and Poor, H. Vincent},
	urldate = {2022-10-17},
	date = {2021-08-15},
}

﻿@inbook{ladia_2019,
	author = {Ladia, Aman},
	booktitle = {Advances in {Intelligent} {Systems} and {Computing}},
	year = {2019},
	month = {jun 25},
	pages = {62--70},
	publisher = {Springer International Publishing},
	title = {Privacy {Centric} {Collaborative} {Machine} {Learning} {Model} {Training} via {Blockchain}},
	url = {http://dx.doi.org/10.1007/978-3-030-23813-1_8},
	doi = {10.1007/978-3-030-23813-1_8},
	abstract = {This paper tackles the issue of data siloing, where organisations are unable to share data with each other because of privacy concerns. Machine Learning models, which could benefit greatly from larger data sets shared between organisations, suffer in this era of data isolation. To solve this problem, a blockchain based implementation is proposed that allows training of machine learning models in a privacy compliant way. Instead of using blockchain in a typical database-style manner, the proposed solution uses blockchain as a means to handle joint ownership and joint control over a computer system known as the Training Machine. The Training Machine, set-up jointly by consortium members, serves as a secure, independent container that accepts data sets and an untrained model as inputs from different entities, trains the model internally, and outputs the trained model without revealing any data to other entities. Data is then deleted automatically. Blockchain ensures that this machine is not under the control of any one entity but is rather controlled transparently by all data-sharing parties. By placing sensitive information in an isolated system, and establishing blockchain based access control, the solution ensures that data is not accessible to any party other than the owner. The paper also shares use cases of this technology, along with a risk analysis and proof of concept.},
}


@inproceedings{kusi_2020,
	author = {Kusi, Goodlet Akwasi and Xia, Qi and Cobblah, Christian Nii Aflah and Gao, Jianbin and Xia, Hu},
	booktitle = {2020 16th {International} {Conference} on {Mobility}, {Sensing} and {Networking} ({MSN})},
	year = {2020},
	month = {12},
	organization = {IEEE},
	title = {Training {Machine} {Learning} {Models} {Through} {Preserved} {Decentralization}},
	url = {http://dx.doi.org/10.1109/MSN50589.2020.00080},
	doi = {10.1109/msn50589.2020.00080},
	abstract = {In the era of big data, fast and effective machine learning algorithms are urgently required for large-scale data analysis. Data is usually created from several parts and stored in a geographically distributed manner, which has stimulated research in the field of distributed machine learning. The traditional master-level distributed learning algorithm involves the use of a trusted central server and focuses on the online privacy model. On the contrary, the specific linear learning model and security issues are not well understood in this column. We built a decentralized advanced-Proof-of-Work (aPoW) algorithm specifically for learning a general predictive model over the blockchain. In aPoW, we establish the data privacy of the differential privacy based schemes to protect each party and propose a secure domain against potential Byzantine attacks at a reduced rate. We explored a technical module in newsprint to consider a universal learning model (linear or non-linear) to provide a secure, confidential decentralized machine learning system called deepLearning Chain. Finally, we introduce deepLearning Chain on blockchain through comprehensive experiments, demonstrate its performance and effectiveness.},
}

@article{xu_2022,
	author = {Xu, Haitao and Wei, Wei and Qi, Yong and Qi, Saiyu},
	journal = {Wireless Communications and Mobile Computing},
	editor = {Souri, Alireza},
	year = {2022},
	month = {jul 26},
	pages = {1--13},
	publisher = {Hindawi Limited},
	title = {Blockchain-{Based} {Crowdsourcing} {Makes} {Training} {Dataset} of {Machine} {Learning} {No} {Longer} {Be} in {Short} {Supply}},
	volume = {2022},
	url = {http://dx.doi.org/10.1155/2022/7033626},
	doi = {10.1155/2022/7033626},
	abstract = {Recently, machine learning has become popular in various fields like healthcare, smart transportation, network, and big data. However, the labelled training dataset, which is one of the most core of machine learning, cannot meet the requirements of quantity, quality, and diversity due to the limitation of data sources. Crowdsourcing systems based on mobile computing seem to address the bottlenecks faced by machine learning due to their unique advantages; i.e., crowdsourcing can make professional and nonprofessional participate in the collection and annotation process, which can greatly improve the quantity of the training dataset. Additionally, distributed blockchain technology can be embedded into crowdsourcing systems to make it transparent, secure, traceable, and decentralized. Moreover, truth discovery algorithm can improve the accuracy of annotation. Reasonable incentive mechanism will attract many workers to provide plenty of dataset. In this paper, we review studies applying mobile crowdsourcing to training dataset collection and annotation. In addition, after reviewing researches on blockchain or incentive mechanism, we propose a new possible combination of machine learning and crowdsourcing systems.},
}


@misc{ding_2022,
	author = {{Shengwen  Ding} and {Chenhui  Hu}},
	title = {Survey on the {Convergence} of {Machine} {Learning} and {Blockchain}},
    year = {2022},
	abstract = {Machine learning (ML) has been pervasively researched nowadays and it has been applied in many aspects of real life. Nevertheless, issues of model and data still accompany the development of ML. For instance, training of traditional ML models is limited to the access of data sets, which are generally proprietary; published ML models may soon be out of date without update of new data and continuous training; malicious data contributors may upload wrongly labeled data that leads to undesirable training results; and the abuse of private data and data leakage also exit. With the utilization of blockchain, an emerging and swiftly developing technology, these problems can be efficiently solved. In this paper, we conduct a survey of the convergence of collaborative ML and blockchain. We investigate different ways of combination of these two technologies, and their fields of application. We also discuss the limitations of current research and their future directions. Keywords---machine learning (ML), blockchain, marketplace, smart contract, incentive mechanism, data privacy},
}

@misc{kurtulmus_2018,
	author = {{A. B. Kurtulmus} and {K. Daniel}},
	title = {Trustless {Machine} {Learning} {Contracts}; {Evaluating} and {Exchanging} {Machine} {Learning} {Models} on the {Ethereum} {Blockchain}},
    year = {2018},
	abstract = {Using blockchain technology, it is possible to create contracts that offer a reward in exchange for a trained machine learning model for a particular data set. This would allow users to train machine learning models for a reward in a trustless manner. The smart contract will use the blockchain to automatically validate the solution, so there would be no debate about whether the solution was correct or not. Users who submit the solutions won't have counterparty risk that they won't get paid for their work. Contracts can be created easily by anyone with a dataset, even programmatically by software agents. This creates a market where parties who are good at solving machine learning problems can directly monetize their skillset, and where any organization or software agent that has a problem to solve with AI can solicit solutions from all over the world. This will incentivize the creation of better machine learning models, and make AI more accessible to companies and software agents.},
}

﻿@inproceedings{chen_2018,
	author = {Chen, Xuhui and Ji, Jinlong and Luo, Changqing and Liao, Weixian and Li, Pan},
	booktitle = {2018 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	year = {2018},
	month = {12},
	organization = {IEEE},
	title = {When {Machine} {Learning} {Meets} {Blockchain}: A {Decentralized}, {Privacy}-preserving and {Secure} {Design}},
	url = {http://dx.doi.org/10.1109/BigData.2018.8622598},
	doi = {10.1109/bigdata.2018.8622598},
	abstract = {With the onset of the big data era, designing efficient and effective machine learning algorithms to analyze large-scale data is in dire need. In practice, data is typically generated by multiple parties and stored in a geographically distributed manner, which spurs the study of distributed machine learning. Traditional master-worker type of distributed machine learning algorithms assumes a trusted central server and focuses on the privacy issue in linear learning models, while privacy in nonlinear learning models and security issues are not well studied. To address these issues, in this paper, we explore the blockchain technique to propose a decentralized privacy-preserving and secure machine learning system, called LearningChain, by considering a general (linear or nonlinear) learning model and without a trusted central server. Specifically, we design a decentralized Stochastic Gradient Descent (SGD) algorithm to learn a general predictive model over the blockchain. In decentralized SGD, we develop differential privacy based schemes to protect each party\textquoteright{}s data privacy, and propose an l-nearest aggregation algorithm to protect the system from potential Byzantine attacks. We also conduct theoretical analysis on the privacy and security of the proposed LearningChain. Finally, we implement LearningChain on Etheurum and demonstrate its efficiency and effectiveness through extensive experiments.},
}

@inbook{fadaeddini_2019,
	author = {Fadaeddini, Amin and Majidi, Babak and Eshghi, Mohammad},
	booktitle = {Communications in {Computer} and {Information} {Science}},
	year = {2019},
	pages = {32--40},
	publisher = {Springer International Publishing},
	title = {Privacy {Preserved} {Decentralized} {Deep} {Learning}: A {Blockchain} {Based} {Solution} for {Secure} {AI}-{Driven} {Enterprise}},
	url = {http://dx.doi.org/10.1007/978-3-030-33495-6_3},
	doi = {10.1007/978-3-030-33495-6_3},
	abstract = {Deep learning and Blockchain attracted the attention of both the research community and the industry. In the financial enterprise by using the Blockchain technology, financial transactions could be performed in shorter periods and with higher transparency and security. In Blockchain ecosystem, there is no need for having a central reliable authority to regulate and control the system. In Blockchain many entities which cannot trust each other in normal conditions can join together to achieve a mutual goal. Deep learning algorithms are currently the best solution for many machine learning applications and provide high accuracy models for robotics, computer vision, smart cities and other AI-driven enterprise. However, availability of more data can boost the performance of deep models considerably. In this paper, a secure decentralized deep learning framework for big data analytics on Blockchain for AI-driven enterprise is proposed. The proposed framework uses the Stellar Blockchain infrastructure for secure decentralized training of the deep models. A Deep Learning Coin (DLC) is used for Blockchain compensation. The security of the proposed framework incentivizes people and organizations to share their valuable data for training the deep neural models while the privacy of their data is preserved.},
}

@inproceedings{goel_2019,
	author = {Goel, Akhil and Agarwal, Akshay and Vatsa, Mayank and Singh, Richa and Ratha, Nalini},
	booktitle = {2019 {IEEE} 10th {International} {Conference} on {Biometrics} {Theory}, {Applications} and {Systems} ({BTAS})},
	year = {2019},
	month = {9},
	organization = {IEEE},
	title = {Securing {CNN} {Model} and {Biometric} {Template} using {Blockchain}},
	url = {http://dx.doi.org/10.1109/BTAS46853.2019.9185999},
	doi = {10.1109/btas46853.2019.9185999},
	abstract = {Blockchain has emerged as a leading technology that ensures security in a distributed framework. Recently, it has been shown that blockchain can be used to convert traditional blocks of any deep learning models into secure systems. In this research, we model a trained biometric recognition system in an architecture which leverages the blockchain technology to provide fault tolerant access in a distributed environment. The advantage of the proposed approach is that tampering in one particular component alerts the whole system and helps in easy identification of \textquoteleft{}any\textquoteright{} possible alteration. Experimentally, with different biometric modalities, we have shown that the proposed approach provides security to both deep learning model and the biometric template.},
}

@article{wang_ai_2020,
	author = {Wang, Qianlong and Guo, Yifan and Wang, Xufei and Ji, Tianxi and Yu, Lixing and Li, Pan},
	journal = {IEEE Internet of Things Journal},
	number = {10},
	year = {2020},
	month = {10},
	pages = {9600--9610},
	publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
	title = {AI at the {Edge}: Blockchain-{Empowered} {Secure} {Multiparty} {Learning} {With} {Heterogeneous} {Models}},
	volume = {7},
	url = {http://dx.doi.org/10.1109/JIOT.2020.2987843},
	doi = {10.1109/jiot.2020.2987843},
	abstract = {Edge computing, an emerging computing paradigm pushing data computing and storing to network edges, enables many applications that require high computing complexity, scalability, and security. In the big data era, one of the most critical applications is multiparty learning or federated learning, which allows different parties to collaborate with each other to obtain better learning models without sharing their own data. However, there are several main concerns about the current multiparty learning systems. First, most existing systems are distributed and need a central server to coordinate the learning process. However, such a central server can easily become a single point of failure and may not be trustworthy. Second, although quite a few schemes have been proposed to study Byzantine attacks, a very common and challenging kind of attack in distributed systems, they generally consider the scenario of learning a global model. However, in fact, all parties in multiparty learning usually have their own local models. The learning methods and security issues, in this case, are not fully explored. In this article, we propose a novel blockchain-empowered decentralized secure multiparty learning system with heterogeneous local models called BEMA. Particularly, we consider two types of Byzantine attacks, and carefully design ``off-chain sample mining'' and ``on-chain mining '' schemes to protect the security of the proposed system. We theoretically prove the system performance bound and resilience under Byzantine attacks. The simulation results show that the proposed system obtains comparable performance with that of conventional distributed systems, and bounded performance in the case of Byzantine attacks.},
}

@misc{wang_2022,
	author = {{Zhilin Wang} and {Qin Hu} and {Ruinian Li} and {Minghui Xu} and {Zehui Xiong}},
	title = {Incentive {Mechanism} {Design} for {Joint} {Resource} {Allocation} in {Blockchain}-based {Federated} {Learning}},
    year = {2022},
	abstract = {Blockchain-based federated learning (BCFL) has recently gained tremendous attention because of its advantages such as decentralization and privacy protection of raw data. However, there has been few research focusing on the allocation of resources for clients in BCFL. In the BCFL framework where the FL clients and the blockchain miners are the same devices, clients broadcast the trained model updates to the blockchain network and then perform mining to generate new blocks. Since each client has a limited amount of computing resources, the problem of allocating computing resources into training and mining needs to be carefully addressed. In this paper, we design an incentive mechanism to assign each client appropriate rewards for training and mining, and then the client will determine the amount of computing power to allocate for each subtask based on these rewards using the two-stage Stackelberg game. After analyzing the utilities of the model owner (MO) (i.e., the BCFL task publisher) and clients, we transform the game model into two optimization problems, which are sequentially solved to derive the optimal strategies for both the MO and clients. Further, considering the fact that local training related information of each client may not be known by others, we extend the game model with analytical solutions to the incomplete information scenario. Extensive experimental results demonstrate the validity of our proposed schemes.},
}

@inproceedings{goncalves_2022,
	author = {De Brito Goncalves, Joao Paulo and Da Silva Villaca, Rodolfo},
	booktitle = {2022 {IEEE} {International} {Conference} on {Blockchain} ({Blockchain})},
	year = {2022},
	month = {8},
	organization = {IEEE},
	title = {A {Blockchained} {Incentive} {Architecture} for {Federated} {Learning}},
	url = {http://dx.doi.org/10.1109/Blockchain55522.2022.00074},
	doi = {10.1109/blockchain55522.2022.00074},
	abstract = {The naive use of Federated Learning (FL) in a distributed environment exposes it to a risk of corruption, whether intentional or not, during the training phase. It happens because of the lack of monitoring of the training increments and difficulty of checking the quality of the training datasets. A very common type of attack of this type is Model Poisoning. To improve the security of the FL structure, we propose a decentralized FL framework based on blockchain, that is, a blockchain-based FL framework to increment the system security using an incentive mechanism to reward good trainers in the form of tokens. The system modeling will be presented as well as its implementation in the Mininet simulator. The validation tests performed to attest its accuracy were executed using the MNIST dataset.},
}

@article{weijie_2022,
author = {Yang, Xun and Tan, Weijie and Peng, Changgen and Xiang, Shuwen and Niu, Kun and Ying, James},
title = {Federated Learning Incentive Mechanism Design via Enhanced Shapley Value Method},
year = {2022},
issue_date = {2022},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2022},
issn = {1530-8669},
url = {https://doi.org/10.1155/2022/9690657},
doi = {10.1155/2022/9690657},
abstract = {Federated learning (FL) is an emerging collaborative machine learning method. In FL processing, the data quality shared by users directly affects the accuracy of the federated learning model, and how to encourage more data owners to share data is crucial. In other words, how to design a good incentive mechanism is the key problem in FL. In this paper, we propose an incentive mechanism based on the enhanced Shapley value method for FL. In the proposed mechanism, the enhanced Shapley value method is proposed to measure income distribution, which takes multiple influence factors as weights. The analytic hierarchy process (AHP) is used to find the corresponding weight value of the influence factors. Finally, the numerical experiments are carried to verify the performance of the proposed incentive mechanism. The results show that compared with the Shapley value method considering the single factor, the income distribution of all participants can better reflect multiple factor contribution when using the enhanced Shapley value method.},
journal = {Wirel. Commun. Mob. Comput.},
month = {jan},
numpages = {11}
}

@ARTICLE{li_bft_2021,  author={Li, Zonghang and Yu, Hongfang and Zhou, Tianyao and Luo, Long and Fan, Mochan and Xu, Zenglin and Sun, Gang},  journal={IEEE Network},   title={Byzantine Resistant Secure Blockchained Federated Learning at the Edge},   year={2021},  volume={35},  number={4},  pages={295-301},  doi={10.1109/MNET.011.2000604}}

@article{khan_2021,
  title={Blockchain smart contracts: Applications, challenges, and future trends},
  author={Shafaq Naheed Khan and Faiza Loukil and Chirine Ghedira and Elhadj Benkhelifa and Anoud I. Bani-Hani},
  journal={Peer-to-Peer Networking and Applications},
  year={2021},
  volume={14},
  pages={2901 - 2925}
}
